{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5f4694",
   "metadata": {},
   "source": [
    "# Assignment 2 — MLflow Experiment Tracking & Model Versioning\n",
    "\n",
    "**Goals (this notebook):**\n",
    "1. Load the versioned dataset (the current `train.csv`/`validation.csv`/`test.csv` under PROJECT_DIR).\n",
    "2. Train and log **three benchmark models** with MLflow, logging AUCPR as the primary selection metric.\n",
    "3. Show how to query MLflow runs and print AUCPR for each trained model.\n",
    "4. Demonstrate model registration (optional; only if an MLflow Model Registry is available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a63dd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tech WorlD\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026/02/16 00:11:29 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/16 00:11:29 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/16 00:11:29 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/16 00:11:29 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/16 00:11:29 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/16 00:11:29 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/16 00:11:30 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/02/16 00:11:30 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2026/02/16 00:11:30 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2026/02/16 00:11:31 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade 1bd49d398cd23 -> b7c8d9e0f1a2, add trace metrics table\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade b7c8d9e0f1a2 -> 5d2d30f0abce, update job table\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade 5d2d30f0abce -> c9d4e5f6a7b8, add routing strategy to endpoints and linkage type to mappings\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade c9d4e5f6a7b8 -> 2c33131f4dae, add online_scoring_configs table\n",
      "2026/02/16 00:11:32 INFO alembic.runtime.migration: Running upgrade 2c33131f4dae -> d3e4f5a6b7c8, add display_name to endpoint_bindings\n",
      "2026/02/16 00:11:33 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/16 00:11:33 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/16 00:11:33 INFO mlflow.tracking.fluent: Experiment with name 'Assignment2_SMS_Spam' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: sqlite:///mlflow.db\n"
     ]
    }
   ],
   "source": [
    "# Optional: install mlflow in notebook environment (prefer terminal)\n",
    "# !pip install mlflow\n",
    "\n",
    "import os, joblib, json\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Project settings (match prepare notebook)\n",
    "PROJECT_DIR = '.'   \n",
    "TRAIN_CSV = os.path.join(PROJECT_DIR, 'train.csv')\n",
    "VAL_CSV = os.path.join(PROJECT_DIR, 'validation.csv')\n",
    "TEST_CSV = os.path.join(PROJECT_DIR, 'test.csv')\n",
    "\n",
    "# MLflow experiment name\n",
    "EXPERIMENT_NAME = \"Assignment2_SMS_Spam\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448e14fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> train, val, test: (3901, 2) (836, 2) (837, 2)\n",
      "Train label distribution: {'ham': 3378, 'spam': 523}\n"
     ]
    }
   ],
   "source": [
    "# Load CSVs created/tracked by DVC (current checked out version in PROJECT_DIR)\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df = pd.read_csv(VAL_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(\"Shapes -> train, val, test:\", train_df.shape, val_df.shape, test_df.shape)\n",
    "print(\"Train label distribution:\", train_df['label'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d9b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for scoring and AUCPR\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def get_positive_scores(pipeline, X):\n",
    "    # Try predict_proba, otherwise decision_function, else fallback to predict\n",
    "    try:\n",
    "        probs = pipeline.predict_proba(X)\n",
    "        # find column index for 'spam' if classes_ are strings\n",
    "        if hasattr(pipeline, 'classes_'):\n",
    "            classes = pipeline.classes_\n",
    "        else:\n",
    "            # some sklearn pipelines place classes_ on the last estimator\n",
    "            last = list(pipeline.named_steps.items())[-1][1]\n",
    "            classes = getattr(last, 'classes_', None)\n",
    "        if classes is not None and 'spam' in classes:\n",
    "            pos_idx = list(classes).index('spam')\n",
    "            return probs[:, pos_idx]\n",
    "        else:\n",
    "            # assume positive class is column index 1\n",
    "            return probs[:, -1]\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pipeline.decision_function(X)\n",
    "        except Exception:\n",
    "            # fallback: predict returns 0/1 -> convert to 0/1 float\n",
    "            preds = pipeline.predict(X)\n",
    "            return (preds == 'spam').astype(float)\n",
    "\n",
    "def compute_aupr(y_true, y_scores):\n",
    "    y_bin = (y_true == 'spam').astype(int)\n",
    "    return average_precision_score(y_bin, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c718a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_mlflow(run_name, pipeline, X_train, y_train, X_val, y_val, params=None):\n",
    "    \"\"\"\n",
    "    Train pipeline, compute AUCPR on validation, log model and metrics to MLflow.\n",
    "    Returns run_id and aupr.\n",
    "    \"\"\"\n",
    "    params = params or {}\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    scores_val = get_positive_scores(pipeline, X_val)\n",
    "    aupr_val = compute_aupr(y_val, scores_val)\n",
    "    # classification metrics (hard preds)\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    report = classification_report(y_val, y_val_pred, output_dict=True)\n",
    "    # log with MLflow\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"aupr_val\", float(aupr_val))\n",
    "        # also log spam f1/precision/recall\n",
    "        if 'spam' in report:\n",
    "            mlflow.log_metric(\"f1_spam_val\", float(report['spam']['f1-score']))\n",
    "            mlflow.log_metric(\"precision_spam_val\", float(report['spam']['precision']))\n",
    "            mlflow.log_metric(\"recall_spam_val\", float(report['spam']['recall']))\n",
    "        # log model artifact\n",
    "        mlflow.sklearn.log_model(pipeline, artifact_path=\"model\")\n",
    "        run_id = run.info.run_id\n",
    "    print(f\"Logged run {run_id} ({run_name}) -> AUCPR (val) = {aupr_val:.4f}\")\n",
    "    return run_id, aupr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de5e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 00:11:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\Tech WorlD\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run 1dc4244162f9435a9c0e88d2c5368ffa (nb_count) -> AUCPR (val) = 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 00:11:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\Tech WorlD\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run dfa3e2ff48954ba080bf9e717be66def (logreg_tfidf) -> AUCPR (val) = 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 00:11:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\Tech WorlD\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run 6999b065dbc540f589b615542ef53940 (rf_tfidf) -> AUCPR (val) = 0.9920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>run_id</th>\n",
       "      <th>aupr_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf_tfidf</td>\n",
       "      <td>6999b065dbc540f589b615542ef53940</td>\n",
       "      <td>0.992001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg_tfidf</td>\n",
       "      <td>dfa3e2ff48954ba080bf9e717be66def</td>\n",
       "      <td>0.985605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb_count</td>\n",
       "      <td>1dc4244162f9435a9c0e88d2c5368ffa</td>\n",
       "      <td>0.973329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                            run_id  aupr_val\n",
       "2      rf_tfidf  6999b065dbc540f589b615542ef53940  0.992001\n",
       "1  logreg_tfidf  dfa3e2ff48954ba080bf9e717be66def  0.985605\n",
       "0      nb_count  1dc4244162f9435a9c0e88d2c5368ffa  0.973329"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define 3 benchmarks (you can replace RandomForest with LinearSVC if desired)\n",
    "pipelines = {\n",
    "    \"nb_count\": Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())]),\n",
    "    \"logreg_tfidf\": Pipeline([('vect', TfidfVectorizer()), ('clf', LogisticRegression(max_iter=2000))]),\n",
    "    \"rf_tfidf\": Pipeline([('vect', TfidfVectorizer()), ('clf', RandomForestClassifier(n_estimators=200, random_state=42))])\n",
    "}\n",
    "\n",
    "X_train = train_df['message']\n",
    "y_train = train_df['label']\n",
    "X_val = val_df['message']\n",
    "y_val = val_df['label']\n",
    "\n",
    "runs = []\n",
    "for name, pipe in pipelines.items():\n",
    "    run_id, aupr = train_and_log_mlflow(name, pipe, X_train, y_train, X_val, y_val, params={\"pipeline\": name})\n",
    "    runs.append({'name': name, 'run_id': run_id, 'aupr_val': aupr})\n",
    "    \n",
    "import pandas as pd\n",
    "display(pd.DataFrame(runs).sort_values('aupr_val', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e79a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>aupr_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6999b065dbc540f589b615542ef53940</td>\n",
       "      <td>rf_tfidf</td>\n",
       "      <td>0.992001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dfa3e2ff48954ba080bf9e717be66def</td>\n",
       "      <td>logreg_tfidf</td>\n",
       "      <td>0.985605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1dc4244162f9435a9c0e88d2c5368ffa</td>\n",
       "      <td>nb_count</td>\n",
       "      <td>0.973329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id      run_name  aupr_val\n",
       "0  6999b065dbc540f589b615542ef53940      rf_tfidf  0.992001\n",
       "1  dfa3e2ff48954ba080bf9e717be66def  logreg_tfidf  0.985605\n",
       "2  1dc4244162f9435a9c0e88d2c5368ffa      nb_count  0.973329"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use MlflowClient to list runs for the experiment\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "run_infos = client.search_runs(experiment_ids=[exp.experiment_id], filter_string=\"\")\n",
    "rows = []\n",
    "for r in run_infos:\n",
    "    rows.append({\n",
    "        'run_id': r.info.run_id,\n",
    "        'run_name': r.data.tags.get('mlflow.runName'),\n",
    "        'aupr_val': r.data.metrics.get('aupr_val')\n",
    "    })\n",
    "df_runs = pd.DataFrame(rows)\n",
    "df_runs = df_runs.sort_values('aupr_val', ascending=False)\n",
    "display(df_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425cd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 520.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6999b065dbc540f589b615542ef53940 (rf_tfidf) -> AUCPR on test: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 670.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dfa3e2ff48954ba080bf9e717be66def (logreg_tfidf) -> AUCPR on test: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 865.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1dc4244162f9435a9c0e88d2c5368ffa (nb_count) -> AUCPR on test: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>aupr_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1dc4244162f9435a9c0e88d2c5368ffa</td>\n",
       "      <td>nb_count</td>\n",
       "      <td>0.982216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6999b065dbc540f589b615542ef53940</td>\n",
       "      <td>rf_tfidf</td>\n",
       "      <td>0.967277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dfa3e2ff48954ba080bf9e717be66def</td>\n",
       "      <td>logreg_tfidf</td>\n",
       "      <td>0.966741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id      run_name  aupr_test\n",
       "2  1dc4244162f9435a9c0e88d2c5368ffa      nb_count   0.982216\n",
       "0  6999b065dbc540f589b615542ef53940      rf_tfidf   0.967277\n",
       "1  dfa3e2ff48954ba080bf9e717be66def  logreg_tfidf   0.966741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate each run's logged model on test set. This downloads the model artifact and loads it.\n",
    "\n",
    "\n",
    "test_X = test_df['message']\n",
    "test_y = test_df['label']\n",
    "\n",
    "final_rows = []\n",
    "for r in df_runs.itertuples():\n",
    "    run_id = r.run_id\n",
    "    # model URI: \"runs:/<run_id>/model\"\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    try:\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        scores_test = get_positive_scores(model, test_X)\n",
    "        aupr_test = compute_aupr(test_y, scores_test)\n",
    "        final_rows.append({'run_id': run_id, 'run_name': r.run_name, 'aupr_test': aupr_test})\n",
    "        print(f\"Run {run_id} ({r.run_name}) -> AUCPR on test: {aupr_test:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load model for run {run_id}: {e}\")\n",
    "\n",
    "display(pd.DataFrame(final_rows).sort_values('aupr_test', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb4d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model version: 1\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "if not df_runs.empty:\n",
    "    best_run_id = df_runs.iloc[0].run_id\n",
    "    model_uri = f\"runs:/{best_run_id}/model\"\n",
    "    model_name = \"Assignment2_SMSSpam\"\n",
    "    try:\n",
    "        client.create_registered_model(model_name)\n",
    "    except Exception as e:\n",
    "        # model may already exist\n",
    "        print(\"create_registered_model: skipped or failed:\", e)\n",
    "    try:\n",
    "        mv = client.create_model_version(name=model_name, source=model_uri, run_id=best_run_id)\n",
    "        print(\"Registered model version:\", mv.version)\n",
    "    except Exception as e:\n",
    "        print(\"Model registration failed (likely no registry configured). Exception:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
